import streamlit as st
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, accuracy_score, confusion_matrix
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import plotly.express as px
import logging
import warnings
import os
warnings.filterwarnings('ignore')

# Set up logging
logging.basicConfig(level=logging.INFO)

# Download NLTK data
@st.cache_resource
def setup_nltk():
    try:
        nltk.download('stopwords', quiet=True)
        nltk.download('punkt', quiet=True)
        return True
    except Exception as e:
        logging.error(f"NLTK setup failed: {str(e)}")
        return False

setup_nltk()

# Set up Streamlit page
st.set_page_config(page_title="SMS Spam Classifier with Ensemble", page_icon="üõ°Ô∏è", layout="wide")

# Simple CSS styling
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #4B0082;
        text-align: center;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f0f0f0;
        padding: 10px;
        border-radius: 8px;
        text-align: center;
        margin-bottom: 10px;
    }
    .prediction-spam {
        background-color: #ff4d4d;
        color: white;
        padding: 10px;
        border-radius: 8px;
        text-align: center;
        font-weight: bold;
    }
    .prediction-ham {
        background-color: #4CAF50;
        color: white;
        padding: 10px;
        border-radius: 8px;
        text-align: center;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

# Text Preprocessor Class
class TextPreprocessor:
    def __init__(self):
        try:
            self.stop_words = set(stopwords.words('english'))
        except:
            self.stop_words = set(['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at'])
    
    def preprocess(self, text):
        if not text or not isinstance(text, str):
            logging.warning("Invalid input text")
            return ""
        text = text.lower()
        text = re.sub(r'http\S+|www\.\S+', 'url', text)
        text = re.sub(r'\d+', 'number', text)
        text = re.sub(r'[^a-zA-Z\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        try:
            words = word_tokenize(text)
        except:
            words = text.split()
        words = [word for word in words if word not in self.stop_words and len(word) > 2]
        return ' '.join(words)
    
    def extract_features(self, text):
        if not text or not isinstance(text, str):
            return {'length': 0, 'has_url': 0}
        return {
            'length': len(text),
            'has_url': int(bool(re.search(r'http\S+|www\.\S+', text)))
        }

# Load dataset (automatically download UCI if not present)
@st.cache_data
def load_dataset():
    dataset_path = 'SMSSpamCollection'
    if not os.path.exists(dataset_path):
        st.info("Downloading UCI SMS Spam Collection dataset...")
        try:
            import urllib.request
            urllib.request.urlretrieve("https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip", "smsspamcollection.zip")
            import zipfile
            with zipfile.ZipFile("smsspamcollection.zip", 'r') as zip_ref:
                zip_ref.extractall(".")
            os.remove("smsspamcollection.zip")
            st.success("Dataset downloaded successfully!")
        except Exception as e:
            logging.error(f"Download failed: {str(e)}")
            st.error("Download failed. Using synthetic data instead.")
            # Synthetic fallback
            texts = [
                "Win $1000 now! Click www.example.com!",
                "Urgent: Verify account at bank.com!",
                "Free offer! Text YES to 12345!",
                "Claim your prize at win.fake.com!",
                "90% off sale! Visit shop.now.com!",
                "Hey, lunch at 1 PM?",
                "Can you grab milk?",
                "Meeting at 2 PM.",
                "Thanks for the help!",
                "Report sent.",
                "Happy birthday!",
                "Running late 10 mins.",
                "See you tomorrow!",
                "Weather looks good.",
                "Congrats on promotion!",
                "Great presentation!",
                "Mom‚Äôs birthday Sunday.",
                "Reschedule dinner?",
                "Flight delayed to 7 PM.",
                "Loved the book!"
            ]
            labels = [1] * 5 + [0] * 15
            return pd.DataFrame({'text': texts, 'label': labels})
    
    try:
        df = pd.read_csv(dataset_path, sep='\t', names=['label', 'text'])
        df['label'] = df['label'].map({'ham': 0, 'spam': 1})
        return df
    except Exception as e:
        logging.error(f"Failed to load dataset: {str(e)}")
        st.error("Could not load dataset. Using synthetic data instead.")
        # Synthetic fallback (same as above)
        texts = [...]  # (omit for brevity, same as above)
        labels = [1] * 5 + [0] * 15
        return pd.DataFrame({'text': texts, 'label': labels})

# Train ensemble model
@st.cache_resource(hash_funcs={TfidfVectorizer: id})
def train_model():
    try:
        df = load_dataset()
        preprocessor = TextPreprocessor()
        df['processed_text'] = df['text'].apply(preprocessor.preprocess)
        feature_data = [preprocessor.extract_features(text) for text in df['text']]
        feature_df = pd.DataFrame(feature_data)
        vectorizer = TfidfVectorizer(max_features=200, stop_words='english')
        X_tfidf = vectorizer.fit_transform(df['processed_text'])
        X = np.hstack([X_tfidf.toarray(), feature_df.values])
        y = df['label'].values
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        xgb_model = XGBClassifier(
            n_estimators=50, max_depth=3, 
            scale_pos_weight=sum(y==0)/sum(y==1), 
            random_state=42, eval_metric='logloss'
        )
        lr_model = LogisticRegression(C=1.0, class_weight='balanced', random_state=42)
        nb_model = MultinomialNB(alpha=0.5)
        ensemble_model = VotingClassifier(
            estimators=[
                ('xgb', xgb_model),
                ('lr', lr_model),
                ('nb', nb_model)
            ],
            voting='soft', weights=[2, 1, 1]
        )
        ensemble_model.fit(X_train, y_train)
        y_pred = ensemble_model.predict(X_test)
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'f1_score': f1_score(y_test, y_pred),
            'predictions': y_pred,
            'y_test': y_test
        }
        return ensemble_model, vectorizer, metrics, df, preprocessor
    except Exception as e:
        logging.error(f"Model training failed: {str(e)}")
        st.error(f"Error training model: {str(e)}")
        return None, None, None, None, None

# App title
st.markdown('<h1 class="main-header">SMS Spam Classifier with Ensemble</h1>', unsafe_allow_html=True)
st.write("A tool to detect spam SMS messages using an ensemble of XGBoost, Logistic Regression, and Naive Bayes.")

# Load model
with st.spinner("Training model..."):
    model, vectorizer, metrics, df, preprocessor = train_model()
    if model is None:
        st.error("Failed to load model. Please refresh the page.")
        model_loaded = False
    else:
        st.success(f"Model trained! F1-Score: {metrics['f1_score']*100:.2f}%")
        model_loaded = True

if model_loaded:
    st.sidebar.markdown("## Performance Metrics")
    st.sidebar.markdown(f"""
    <div class="metric-card">
        <strong>F1-Score:</strong> {metrics['f1_score']*100:.2f}%<br>
        <strong>Accuracy:</strong> {metrics['accuracy']*100:.2f}%
    </div>
    """, unsafe_allow_html=True)
    options = st.sidebar.radio("Select Section:", ["Home", "Classify", "Results"])
    if options == "Home":
        st.markdown("## Welcome to the SMS Spam Classifier")
        st.write("""
        This tool uses an ensemble of three machine learning models (XGBoost, Logistic Regression, and Naive Bayes) 
        to detect spam SMS messages. Enter a message in the 'Classify' section to check if it's spam or ham.
        The 'Results' section shows the model's performance.
        """)
        st.markdown(f"""
        <div class="metric-card">
            <strong>Dataset Size:</strong> {len(df)} messages<br>
            <strong>Spam:</strong> {sum(df['label'])} ({sum(df['label'])/len(df)*100:.1f}%)<br>
            <strong>Ham:</strong> {len(df) - sum(df['label'])}
        </div>
        """, unsafe_allow_html=True)
    elif options == "Classify":
        st.markdown("## Classify an SMS Message")
        user_input = st.text_area("Enter SMS message:", "Win $1000 now! Click www.example.com!", height=100)
        if st.button("Check Message"):
            if user_input.strip():
                processed_text = preprocessor.preprocess(user_input)
                features = preprocessor.extract_features(user_input)
                tfidf_features = vectorizer.transform([processed_text])
                combined_features = np.hstack([tfidf_features.toarray(), np.array([list(features.values())])])
                prediction = model.predict(combined_features)[0]
                confidence = model.predict_proba(combined_features)[0][prediction] * 100
                if prediction == 1:
                    st.markdown(f'<div class="prediction-spam">üö® SPAM DETECTED! (Confidence: {confidence:.1f}%)</div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div class="prediction-ham">‚úÖ LEGITIMATE MESSAGE (Confidence: {confidence:.1f}%)</div>', unsafe_allow_html=True)
                st.markdown("### Message Features")
                st.write(f"**Length:** {features['length']} characters")
                st.write(f"**Has URL:** {'Yes' if features['has_url'] else 'No'}")
            else:
                st.warning("Please enter a valid message.")
    elif options == "Results":
        st.markdown("## Model Performance")
        st.write("The confusion matrix shows how well the ensemble model classifies spam and ham messages.")
        cm = confusion_matrix(metrics['y_test'], metrics['predictions'])
        fig = px.imshow(
            cm, text_auto=True, aspect="auto", color_continuous_scale='Blues',
            title='Confusion Matrix', labels=dict(x="Predicted", y="Actual"), x=['Ham', 'Spam'], y=['Ham', 'Spam']
        )
        st.plotly_chart(fig, use_container_width=True)

# Footer
st.markdown("""
<div style='text-align: center; color: #666; padding: 10px;'>
    <h4>SMS Spam Classifier with Ensemble</h4>
    <p>Built for college project using Python, Scikit-learn, XGBoost, NLTK, and Streamlit</p>
</div>
""", unsafe_allow_html=True)
